\documentclass{edm_template}
%\documentclass[11pt,twocolumn]{article}
\usepackage{amsmath}
\usepackage{adjustbox}
\usepackage{paralist}
\usepackage{array}
\usepackage{apacite}
\usepackage{multirow}
\usepackage{dcolumn}
\usepackage{array}
\usepackage{kbordermatrix}
\usepackage{balance}
\usepackage{float}
\DeclareMathOperator*{\argmax}{arg\,max}
    
\begin{document}

\title{Boosted Decision Tree for Q-matrix Refinement}
\numberofauthors{2}
\author{
\alignauthor
Peng Xu\\
       \affaddr{Polytechnique Montreal}\\
       \email{\large\sffamily peng.xu@polymtl.ca}
\alignauthor
Michel C. Desmarais\\
       \affaddr{Polytechnique Montreal}\\
       \email{\large\sffamily michel.desmarais@polymtl.ca}
}
\maketitle

\begin{abstract}
In recent years, substantial improvements were obtained in the effectiveness of data driven algorithms to validate the mapping of items to skills, or the Q-matrix.  In the current study we use ensemble algorithms on top of existing Q-matrix refinement algorithms to improve their performance.  We combine the boosting technique with a decision tree.  The results show that the improvements from both the decision tree and Adaboost add up and yield substantial gains over the best performance of individual q-matrix refinement algorithm.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
A Q-matrix, as proposed by Tatsuoka \cite{tatsuoka1983rule}, is a term commonly used in the literature of psychometrics and cognitive modeling that refers to a binary matrix which shows a correspondence between items and their latent attributes. Items can be questions or exercises proposed to students, and latent attributes are skills needed to succeed these items. Usually, a Q-matrix is defined by a domain expert. However, this task is non trivial and there might be errors, which in turn will result in erroneous diagnosis of students knowledge states \cite{rupp2008effects,madison2015effects}. Therefore, better means to validate a Q-matrix is a highly desirable goal.

A fair number of algorithms have emerged in the last decade to validate an expert given Q-matrix based on empirical data \cite<see for eg.~recent work from>{chen2015statistical,de2015general}.  \citeA{desmarais2015combining} showed that Q-matrix validation algorithms can be combined using an ensemble learning technique.  They used a decision tree and the results show a substantial and systematic performance gain over the best algorithm, in the range of 50\% error reduction for real data, even though the best algorithm is not always the same for different Q-matrices.  We pursue this work along the lines of using ensemble learning, or meta learning techniques, this time using boosting over the decision tree.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\raggedright Three techniques to Q-matrix validation}

Our approach relies on meta-learning algorithm whose principle is to take the output of existing algorithms and apply a learning algorithm to improve upon their output.  In our case, the approach combines a decision tree trained on the output of Q-matrix validation algorithms with boosting, a re-sampling process in the training of the decision tree to improve its accuracy.  In this section, we first describe the Q-matrix validation techniques.

\subsection{minRSS}
The first technique is from \citeA{chiu2013nonparametric}.

For a given Q-matrix, there is an ideal response pattern for a given a student skills mastery profile. This ideal response pattern only relies on Q-matrix given student profile. That is, if there are no slip and guess factors, then the response pattern for every category of student profile is fixed. The difference between the real response pattern and the ideal response pattern represents a measure of fit for the Q-matrix.  The most common metric for binary data is Hamming distance, that is
$$ d_h(r,\eta)=\sum_{j=1}^{J}|r_j-\eta_j|$$
where $r$ is the real response vector while $\eta$ is the ideal response vector. $J$ is the number of latent skills. \cite{chiu2013nonparametric} considered a more refined metric. The idea is if an item has a smaller variance (or entropy), then it should be given higher weight. The formula is
$$ d_{\omega h}(r,\eta)=\sum_{j=1}^{J}\frac{1}{\bar{p_j}(1-\bar{p_j})}|r_j-\eta_j|$$
where $\bar{p_j}$ is the proportion of correct answers of item $j$. Equipped with this metric, we can find the most approximate ideal response matrix and then find the corresponding profile matrix $A$. First, a squared sum of errors for each item $k$ can be computed by
$$ RSS_k=\sum_{i=1}^{N}(r_{ik}-\eta_{ik})^2$$
where $N$ is the number of respondents. Then, the item with the highest $RSS$ is chosen to update its correspondent q-vector. All the other possible q-vectors are tested to calculate their $RSS$ and the q-vector giving the lowest $RSS$ is chosen to replace the original one. That is why we name this method minRSS. The Q-matrix is changed and the whole process repeated, but the previously changed q-vector is eliminated from the next round of running. The whole procedure terminates until the $RSS$ for each item no longer changes.
This method  was shown by \citeA{wang2015consistency} to yield good performance under different underlying conjunctive models.

\subsection{maxDiff}
Under the setting of DINA model, for every item $j$, there are two model parameters, slip $s_j$ and guess $g_j$. \citeA{de2008empirically} proposed that a correctly specified q-vector for item $j$ should maximize the difference of probabilities of correct response between examinees who have all the required attributes and those who do not. That is, $q_j$ is the correct q-vector if
\begin{equation} 
\begin{split}
q_j & =\argmax_{\alpha _l}[P(X_j=1|\xi_{ll'}=1)-P(X_j=1|\xi_{ll'}=0)]
\\
& =\argmax_{\alpha _l}[\delta_{jl}]
\end{split}
\end{equation}
where $\xi_{ll'}=\prod_{k=1}^{K}\alpha_{l'k}^{\alpha_{lk}}$ for $K$ total number of skills. An interesting observation is that since $P(X_j=1|\xi_{ll'}=1)=1-s_j$ and $P(X_j=1|\xi_{ll'}=0)=g_j$, then $$q_j=\argmax_{\alpha _l}[1-(s_j+g_j)]$$ 
that is, maximizing the difference is equivalent to minimize the sum of the slip and guess parameters. A natural idea is to test all q-vectors to find the maximum $\delta_{jl}$ but that is computationally expensive. \citeA{de2008empirically} proposed a greedy algorithm that adds skills into a q-vector sequentially. First, $\delta_{jl}$ is calculated for all q-vectors which contains only one skill and the one with biggest $\delta_{jl}$ is chosen. Then, $\delta_{jl}$ is calculated for all q-vectors which contains two skills including the previously chosen one. Again the q-vector with the biggest $\delta_{jl}$ is chosen. This whole process is repeated until no addition of skills increases $\delta_{jl}$. However, this algorithm requires knowing $s_j$ and $g_j$ in advance. For real data, they are calculated by EM (Expectation Maximization) algorithm \cite{de2009dina}.  

\subsection{ALSC}
ALSC (Conjunctive Alternating Least Square Factorization) is a common matrix Factorization (MF). \citeA{desmarais2013matrix} proposed to factorize student test results into a Q-matrix and a skils-student matrix with ALSC. 

Contrary to the other two methods, it does not rely on the DINA model as it has no slip and guess parameters.  ALSC decomposes the results matrix $\mathbf{R}_{m \times n}$ of~$m$ items by~$n$ students as the inner product two smaller matrices:
\begin{equation}
  \mathbf{\neg {R}} = \mathbf{Q} \, \neg \mathbf{S} \label{eq:nmf}
\end{equation}
where $\neg \mathbf{R}$ is the negation of the results matrix ($m$~items by $n$~students),  $\mathbf{Q}$ is the $m$~items by $k$~skills Q-matrix, and~$\neg \mathbf{S}$ is negation of the the mastery matrix of $k$~skills by $n$~students (normalized for rows columns to sum to~1).  By negation, we mean the 0-values are transformed to~1, and non-0-values to~0.  Negation is necessary for a conjunctive Q-matrix.

The factorization consists of alternating between estimates of~$\mathbf{S}$ and~$\mathbf{Q}$ until convergence.  Starting with the initial expert defined Q-matrix, $\mathbf{{Q}}_0$, a least-squares estimate of~$\mathbf{S}$ is obtained:
\begin{equation}
  \neg \mathbf{\hat{S}}_0 = (\mathbf{Q}_0^{\mathrm{T}}  \, \mathbf{Q}_0)^{-1} \, \mathbf{Q}_0^{\mathrm{T}} \, \neg \mathbf{R} \label{eq:shat}
\end{equation}
Then, a new estimate of the Q-matrix, $\mathbf{\hat{Q}}_1$, is again obtained by the least-squares estimate:
\begin{equation}
  \mathbf{\hat{Q}}_1 = \neg \mathbf{R} \, \neg \mathbf{\hat{S}}_0^{\mathrm{T}} \, (\neg \mathbf{\hat{S}}_0 \, \neg \mathbf{\hat{S}}_0^{\mathrm{T}})^{-1} \label{eq:qhat}
\end{equation}
And so on until convergence.  Alternating between equations~(\ref{eq:shat}) and~(\ref{eq:qhat}) yields progressive refinements of the matrices~$\mathbf{\hat{Q}}_i$ and ~$\mathbf{\hat{S}}_i$ that more closely approximate~$\mathbf{R}$ in equation~(\ref{eq:nmf}).  The final~$\mathbf{\hat{Q}_i}$ is rounded to yield a binary matrix.

\subsection{Decision Tree}

Decision tree is a well-know technique in machine learning and it often serves as an ensemble learning algorithm to combine individual models into a more powerful model. It uses a set of feature variables (individual model predictions) to predict a single target variable (output variable). There are several decision tree algorithms, such as ID3 \cite{quinlan1986induction}, C4.5 \cite{quinlan1993c4}, CART \cite{breiman1984classification}. We used \texttt{rpart} function from the R package of the same name \cite{therneau2015rpart}. It implements the CART algorithm. This algorithm divides the learning process into two phases. The first phase is for feature selection, or tree growing, during which the feature variables are chosen sequentially according to Gini impurity \cite{murphy2012machine}. Then in the second phase, the pruning phase, deep branches are split into wider ones to avoid overfitting. 

A decision tree is a supervised learning technique and therefore requires training data. To obtain training data of sufficient size, \citeA{desmarais2015combining} use synthetic data from Q-matrices generated by permutations of the perturbated Q-matrix. Since the ground-truth Q-matrix of synthetic data is known, it becomes possible to generate training data containing the class label.  The training set for decision tree can take this form:

\begin{tabular}{ c| c c c l c}
 & \multicolumn{3}{c}{Algorithm target prediction} & & Other factors\\
\cline{2-4} \cline{6-6}
  Target & minRSS & maxDiff & ALSC && ...\\
  \hline
  1 & 1 & 0 & 1 &&  ...\\
  0 & 0 & 1 & 0 &&  ...\\
  ... &... &... &... && ...\\
\end{tabular}

The other factors considered to help the decision tree to improve prediction are the number of skills per row (SR), number of skills per column (SC). Moreover, a feature named \textit{stickiness} which measures the rigidity of cells under each validation methods. Stickiness represents the rate of a given algorithm's false positives for a given cell of a Q-matrix.  The rate is measured by ``perturbating'' in turn each and every cell of the Q-matrix, and by counting the number of times the cell is a false positive.  The decision tree can use the stickiness factor as an indicator of the reliability of a given Q-matrix refinement algorithm suggested value for a cell.  Obviously, if a cell's stickiness value is high, the reliability of the algorithm's suggestion will be lower.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Boosting}

The current work extends the idea of using a decision tree, a meta-learning technique, with another meta-learning technique named boosting.

Boosting is a well known technique in machine learning. It lifts a weak classifier to strong classifier. The whole process is sequential. Each time the classifier is trained, the weights of the misclassified data are increased in the loss function and fed to the next round of training. The final classifier is a weighted sum of all classifiers learned in this process. That is,
$$ f(x)=\sum\limits_{m=1}^M\alpha_mG_m(x)$$
in which $G_m(x)$ and $\alpha_m$  are the classifier and its correspondent coefficient obtained in the $m$-th step. The most famous algorithm for boosting is Adaboost \cite{freund1997decision} and it is used in this research to improve the result obtained by \citeA{desmarais2015combining}. The result is reported in section~\ref{sec:result}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology and Performance Criterion}

To estimate the ability of an algorithm to validate a Q-matrix, we perturbate a ``correct'' Q-matrix and verify if the algorithm is able to recover this correct matrix by identifying the cells that were perturbated while avoiding to classify unperturbated cells as perturbated.    In this experiment, only one perturbation is introduced.  For synthetic data, the ``correct'' matrix is known and is the one used in the generation of the data.  For real data, we assume the expert is the correct one, albeit it may contain errors.

In order to use standard performance measure, we define the following categories of correct and incorrect classifications as the number of:
\begin{compactitem}
\item \textbf{True Positives (TP)}: perturbed cell correctly recovered
\item \textbf{True Negatives (TN)}: non perturbed cell left unchanged
\item \textbf{False Positives (FP)}: non perturbed cell incorrectly recovered
\item \textbf{False Negatives (FN)}: perturbed cell left unchanged
\end{compactitem}

In order to give equal weight to perturbed and unperturbed cells, we use an F-score. The F-score is defined as
$$ F=2\cdot \frac{precision \cdot recall}{precision + recall}$$
		$$ precision=\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$$
		$$ recall=\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dataset}

\begin{table}
  \caption{Q-matrix for validation}\label{tab:qm}
  \begin{tabular}{|ccccp{3cm}<{\raggedright}|}
  \hline
   \multirow{2}{*}{\multicolumn{1}{c}{\textbf{Name}}} &
   \multicolumn{3}{c}{\raisebox{0pt}[2.5ex][1ex]{\bf Number of}} &
   \multirow{2}{*}{\multicolumn{1}{>{\centering}p{3cm}}{\textbf{Description}}} \\
  \cline{2-4}
  & Skills &  Items & Cases & \\  
  	\hline
QM1 & 3 & 11 & 536 & {Expert driven from \cite{henson2009defining}} \\
	\hline
QM2 & 3 & 11 & 536 & {Expert driven from \cite{de2008empirically}} \\  
 	\hline
QM3 & 5 & 11 & 536 & {Expert driven from \cite{CDM}} \\  
  	\hline 
QM4 & 3 & 11 & 536 & {Data driven, SVD based} \\  
  	\hline
  	\end{tabular}
\end{table}

For the sake of comparison, we use the same datasets as the ones used in \citeA{desmarais2015combining}.  Table~\ref{tab:qm} provides the basic information and source of each dataset. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Result}\label{sec:result}

\newcolumntype{R}[2]{%
    >{\adjustbox{angle=#1,lap=\width-#2}\bgroup}%
    l%
    <{\egroup}%
}
\newcommand*\rot{\multicolumn{1}{R{60}{1em}}}% no optional argument here, please!
\newcommand{\rottwo}[2]{\multicolumn{1}{R{60}{#1}}{#2}}% no optional argument here, please!

\begin{table}
\caption{Results for synthetic data}\label{tab:res:synth}
\centering
\begin{tabular}{ccc@{\extracolsep{4pt}}cc@{\extracolsep{2pt}}>{(}c<{\%)}c@{\extracolsep{2pt}}>{(}D{.}{.}{1}<{\%)}}
  \hline
  \hline
& \multicolumn{3}{c}{\raisebox{0pt}[2.5ex]{\textbf{Individual}}} & \multicolumn{4}{c}{\textbf{Ensemble}}\\
\cline{2-4} \cline{5-8}
\raisebox{0pt}[2.5ex]{\textbf{QM}} & {\rot{\textbf{minRSS}}} & {\rot{\textbf{maxDiff}}} & {\rot{\textbf{ALSC}}} & \multicolumn{2}{c}{\rottwo{4em}{\parbox{4em}{\textbf{DT (\%Gain)}}}} & \multicolumn{2}{c}{\rottwo{4em}{\parbox{4em}{\textbf{BDT (\%Gain)}}}} \\   
\hline
\hline
\multicolumn{8}{c}{\raisebox{0pt}[2.5ex][1.5ex]{\textbf{Accuracy of perturbated cells}}}\\
 1 & 0.809 & 0.465 & 0.825 & 0.946  & 69.4 & 0.951  & 8.4 \\
 2 & 0.069 & 0.259 & 0.359 & 0.828  & 73.2 & 0.903  & 43.5 \\
 3 & 0.961 & 0.488 & 0.953 & 1.000  & 99.7 & 1.000  & 0.0 \\  
 4 & 0.903 & 0.489 & 0.853 & 0.956  & 54.3 & 0.971  & 33.9 \\  
\hline
\raisebox{0pt}[2.5ex]{$\mathbf{\overline{X}}$} & 0.685 & 0.425 & 0.747 & 0.933  & 74.2 & 0.956  & 21.5 \\ 
\hline
\hline
\multicolumn{8}{c}{\raisebox{0pt}[2.5ex][1.5ex]{\textbf{Accuracy of non perturbated cells}}}\\ 
 1 & 0.970 & 0.558 & 0.387 & 0.990  & 65.1 & 0.990  & 0.0 \\ 
 2 & 0.987 & 0.529 & 0.431 & 0.989  & 20.5 & 0.996  & 59.1 \\
 3 & 0.950 & 0.258 & 0.736 & 0.994  & 88.9 & 1.000  & 100.0 \\
 4 & 0.966 & 0.559 & 0.391 & 0.997  & 92.2 & 0.998  & 19.2 \\ 
\hline
\raisebox{0pt}[2.5ex]{$\mathbf{\overline{X}}$} & 0.968 & 0.476 & 0.486 & 0.993  & 66.7 & 0.996  & 44.6 \\ 
\hline
\hline
\multicolumn{8}{c}{\raisebox{0pt}[2.5ex][1.5ex]{\textbf{F-score}}}\\
 1 & 0.882 & 0.507 & 0.527 & 0.968  & 72.4 & 0.970  & 7.4 \\
 2 & 0.128 & 0.348 & 0.392 & 0.902  & 83.8 & 0.947  & 46.1 \\
 3 & 0.955 & 0.337 & 0.831 & 0.997  & 93.5 & 1.000  & 100.0 \\ 
 4 & 0.934 & 0.522 & 0.536 & 0.976  & 64.0 & 0.984  & 33.6 \\
  \hline
\raisebox{0pt}[2.5ex]{$\mathbf{\overline{X}}$} & 0.725 & 0.429 & 0.571 & 0.961  & 78.4 & 0.975  & 46.8 \\ 
  \hline
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Results for real data}\label{tab:res:real}
\centering
\begin{tabular}{c@{}c@{\hspace{1ex}}c@{\extracolsep{4pt}}cc@{\extracolsep{2pt}}>{(}D{.}{.}{1}<{\%)}@{\hspace{5ex}}c@{\extracolsep{2pt}}>{(}D{.}{.}{1}<{\%)}}
  \hline
  \hline
& \multicolumn{3}{c}{\raisebox{0pt}[2.5ex]{\textbf{Individual}}} & \multicolumn{4}{c}{\textbf{Ensemble}}\\
\cline{2-4} \cline{5-8}
\raisebox{0pt}[2.5ex]{\textbf{QM}} & {\rot{\textbf{minRSS}}} & {\rot{\textbf{maxDiff}}} & {\rot{\textbf{ALSC}}} & \multicolumn{2}{c}{\rottwo{4em}{\parbox{4em}{\textbf{DT (\%Gain)}}}} & \multicolumn{2}{c}{\rottwo{4em}{\parbox{4em}{\textbf{BDT (\%Gain)}}}} \\   
\hline
\hline
\multicolumn{8}{c}{\raisebox{0pt}[2.5ex][1.5ex]{\textbf{Accuracy of perturbated cells}}}\\
 1 & 0.485 & 0.167 & 0.515 & 0.758 & 50.0 & 0.758 & 0.0 \\ 
 2 & 0.345 & 0.093 & 0.564 & 0.618 & 12.5 & 0.764 & 38.1 \\ 
 3 & 0.212 & 0.091 & 0.364 & 0.818 & 71.4 & 0.818 & 0.0 \\  
 4 & 0.394 & 0.111 & 0.576 & 0.576 & 0.0 & 0.818 & 57.1 \\ 
\hline
\raisebox{0pt}[2.5ex]{$\mathbf{\overline{X}}$} & 0.359 & 0.115 & 0.505 & 0.692 & 37.5 & 0.789 & 17.7 \\ 
\hline
\hline
\multicolumn{8}{c}{\raisebox{0pt}[2.5ex][1.5ex]{\textbf{Accuracy of non perturbated cells}}}\\
 1 & 0.435 & 0.670 & 0.418 & 0.606 & -19.4 & 0.606 & 0.0 \\
 2 & 0.875 & 0.929 & 0.110 & 0.956 & 37.9 & 0.966 & 21.4 \\
 3 & 0.661 & 0.830 & 0.219 & 0.785 & -26.2 & 0.752 & -15.1 \\  
 4 & 0.520 & 0.889 & 0.148 & 0.546 & -308.7 & 0.658 & 24.7 \\ 
\hline
\raisebox{0pt}[2.5ex]{$\mathbf{\overline{X}}$} & 0.623 & 0.829 & 0.224 & 0.723 & -79.1 & 0.746 & 7.8 \\
\hline
\hline
\multicolumn{8}{c}{\raisebox{0pt}[2.5ex][1.5ex]{\textbf{F-score}}}\\
 1 & 0.459 & 0.267 & 0.461 & 0.673 & 39.4 & 0.673 & 0.0 \\
 2 & 0.495 & 0.168 & 0.184 & 0.751 & 50.6 & 0.853 & 40.9 \\
 3 & 0.321 & 0.164 & 0.273 & 0.801 & 70.7 & 0.784 & -8.7 \\ 
 4 & 0.448 & 0.198 & 0.235 & 0.560 & 20.3 & 0.730 & 38.5 \\
  \hline
\raisebox{0pt}[2.5ex]{$\mathbf{\overline{X}}$} & 0.431 & 0.199 & 0.288 & 0.696 & 33.45 & 0.760 &23.8 \\ 
  \hline
\hline
\end{tabular}
\end{table}

The results of applying Adaboost over the decision tree (DT) are reported in table~\ref{tab:res:synth} for synthetic data and Table~\ref{tab:res:real} for real data. The individual results of each algorithm are reported (minRSS, maxDiff, and ALSC), along with the decision tree (DT) and the boosted decision tree (BDT).  Different improvement over baselines are reported as ``\%Gain'': the DT improvement over the \textbf{best} of the three individual algorithm, and the BDT improvement of the BT performance.

Let us focus on the F-Score which is the most informative since it combines results of the perturbed and non perturbed cells of the Q-matrix.  For synthetic data, the error reduction of boosting over the gain from the decision tree is substantially improved for all Q-matrices. The range of improvement is from 7\% to 100\%.  For real data, two of the four Q-matrices show substantial improvements of around 40\%, whereas the other two show no improvements, even a decrease of 9\% for Q-matrix~3 which is characterized by a single skill per item.  Note however that we assume the expert Q-matrices are correct and that violation of this assumption could negatively affect some of the Q-matrices scores for real data.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

This study shows that the gain obtained from combining the output of multiple Q-matrix refinement algorithms with a decision tree can be further improved with boosting.  The results for synthetic data show an F-score error reduction of close to 50\% on average for all four Q-matrices, and a 24\% reduction for real data.  

An important advantage of the meta-learning approach outlined here is that it can apply to any combination of algorihtms to validate Q-matrices.  Future work could look into combining more than the three algorithms of this study, and add new algorithms that potentially outperform them. And based on the current results, we would expect to make supplementary gains over any of them.

However, an important category of data over which we would like to apply this approach is for dynamic student performance data, where learning occurs.  Approach such as \citeA{matsudamachine2015} which combines ... as well as \citeA{durand2015evaluation} ... [to complete]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\balance
\bibliographystyle{apacite}
\bibliography{biblio}

\end{document}
